{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "executionInfo": {
     "elapsed": 6182325,
     "status": "ok",
     "timestamp": 1749206695093,
     "user": {
      "displayName": "Gabriel Ortega-Solis",
      "userId": "18125736399926922342"
     },
     "user_tz": -120
    },
    "id": "WOGWFb-Ot95v",
    "outputId": "fba3f505-b2c2-4f38-e4e0-93f4d15da9bd"
   },
   "source": [
    "# NDVI EVI Statistics Processing Script\n",
    "\n",
    "**Authors:** Gabriel Ortega & Michela Perrone\n",
    "\n",
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1750059182353,
     "user": {
      "displayName": "Gabriel Ortega-Solis",
      "userId": "18125736399926922342"
     },
     "user_tz": -120
    },
    "id": "cJaWua0uVrU5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import ee\n",
    "import geemap\n",
    "ee.Authenticate()\n",
    "ee.Initialize(project='gortega-research')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-HV0qSQVrU7"
   },
   "source": [
    "## 1. Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1750059182358,
     "user": {
      "displayName": "Gabriel Ortega-Solis",
      "userId": "18125736399926922342"
     },
     "user_tz": -120
    },
    "id": "_tx0anqAVrU8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "INPUT_FOLDER = \"edge_bck\"          \n",
    "EXPORT_FOLDER = \"NEW_GEE_MODIS_Stats\"  \n",
    "\n",
    "# Processing Parameters\n",
    "START_YEAR = 2000\n",
    "END_YEAR = 2024\n",
    "BATCH_SIZE = 50                    # Process 50 WDPA files per Earth Engine task\n",
    "SIMPLIFY_TOLERANCE = 0.001         # Degrees (approx 100m). Reduces vertices to prevent payload errors.\n",
    "\n",
    "# MODIS Configuration\n",
    "MODIS_COLLECTION = 'MODIS/061/MOD13Q1' # Consider 'MODIS/061/MOD13Q1' for Collection 6.1\n",
    "SCALE_FACTOR = 0.0001\n",
    "BANDS = ['NDVI', 'EVI']\n",
    "QA_BAND = 'SummaryQA'\n",
    "\n",
    "# GPKG Layer Name\n",
    "# Critical: Matches the specific layer in your GPKG to avoid ambiguity\n",
    "TARGET_LAYER_NAME = 'sql_statement' \n",
    "\n",
    "current_date = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# Resume Processing\n",
    "# Should be none if I don't want to skip any files\n",
    "START_FROM_WDPAID = 145814"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvea2gL_VrU9"
   },
   "source": [
    "## 2. Function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1750059182360,
     "user": {
      "displayName": "Gabriel Ortega-Solis",
      "userId": "18125736399926922342"
     },
     "user_tz": -120
    },
    "id": "QvlpR9dnVrU9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def check_queue_and_wait(max_tasks=100):\n",
    "    \"\"\"\n",
    "    Pauses execution if too many tasks are running (default limit 100).\n",
    "    Prevents overloading the local script or hitting strict EE rate limits.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            tasks = ee.batch.Task.list()\n",
    "            active_tasks = [t for t in tasks if t.state in ['READY', 'RUNNING']]\n",
    "            if len(active_tasks) < max_tasks:\n",
    "                break\n",
    "            print(f\"Queue busy ({len(active_tasks)} active). Waiting 60s...\")\n",
    "            time.sleep(60)\n",
    "        except Exception as e:\n",
    "            print(f\"Queue check failed: {e}. Retrying in 30s...\")\n",
    "            time.sleep(30)\n",
    "\n",
    "def read_and_clean_gpkg(filepath):\n",
    "    \"\"\"\n",
    "    Reads a GPKG, selecting the correct layer and simplifying geometry.\n",
    "    Returns a GeoDataFrame or None if invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to read the specific layer to avoid ambiguity warnings\n",
    "        try:\n",
    "            gdf = gpd.read_file(filepath, layer=TARGET_LAYER_NAME)\n",
    "        except ValueError:\n",
    "            # Layer not found, try default reading\n",
    "            gdf = gpd.read_file(filepath)\n",
    "        \n",
    "        if gdf.empty:\n",
    "             return None\n",
    "\n",
    "        # Resume from START_FROM_WDPAID if specified\n",
    "        if START_FROM_WDPAID is not None:\n",
    "            # Ensure column exists (case-insensitive check could be added if needed, but 'wdpaid' is standard)\n",
    "            if 'wdpaid' in gdf.columns:\n",
    "                # Convert to numeric just in case IDs were loaded as strings\n",
    "                gdf['wdpaid'] = pd.to_numeric(gdf['wdpaid'], errors='coerce')\n",
    "                # Filter: Keep only IDs >= the start value\n",
    "                gdf = gdf[gdf['wdpaid'] >= START_FROM_WDPAID]\n",
    "            \n",
    "            # If the file contains only skipped IDs, gdf will be empty\n",
    "            if gdf.empty:\n",
    "                return None\n",
    "\n",
    "        # Simplify geometry to reduce to avoid hitting size limit\n",
    "        gdf['geometry'] = gdf.geometry.simplify(tolerance=SIMPLIFY_TOLERANCE)\n",
    "        \n",
    "        # Add source filename for tracking results back to the original file\n",
    "        gdf['source_file'] = os.path.basename(filepath)\n",
    "        \n",
    "        return gdf\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {os.path.basename(filepath)}: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_yearly_composite(year, roi):\n",
    "    \"\"\"\n",
    "    Creates a 90th percentile composite for the given year and ROI.\n",
    "    Applies QA masking for valid pixels.\n",
    "    \"\"\"\n",
    "    collection = ee.ImageCollection(MODIS_COLLECTION) \\\n",
    "        .filterDate(f'{year}-01-01', f'{year+1}-01-01') \\\n",
    "        .filterBounds(roi)\n",
    "\n",
    "    def mask_quality(image):\n",
    "        qa = image.select(QA_BAND)\n",
    "        # Mask: 0 = Good Data. \n",
    "        # You can add .or(qa.eq(1)) for 'Marginal' data if coverage is too low.\n",
    "        mask = qa.eq(0) \n",
    "        return image.updateMask(mask).multiply(SCALE_FACTOR).copyProperties(image, ['system:time_start'])\n",
    "\n",
    "    # 90th percentile reduces cloud/shadow artifacts effectively for vegetation indices\n",
    "    composite = collection.map(mask_quality).select(BANDS).reduce(ee.Reducer.percentile([90]))\n",
    "    \n",
    "    # Rename bands back to standard names (remove '_p90' suffix created by reducer)\n",
    "    return composite.rename(BANDS)\n",
    "\n",
    "def submit_batch_export(batch_fc, batch_index, years):\n",
    "    \"\"\"\n",
    "    Processes a batch of polygons over all years and submits ONE export task.\n",
    "    \"\"\"\n",
    "    accumulated_results = []\n",
    "    \n",
    "    # Helper to get geometry of the whole batch for efficient image filtering\n",
    "    batch_bounds = batch_fc.geometry().bounds()\n",
    "\n",
    "    # Loop through years locally to build the computation graph\n",
    "    for year in range(years[0], years[1] + 1):\n",
    "        # Get image for this year\n",
    "        img = get_yearly_composite(year, batch_bounds)\n",
    "        \n",
    "        # reduceRegions is efficient for FeatureCollections\n",
    "        # It appends the stats as properties to each feature in the batch\n",
    "        stats = img.reduceRegions(\n",
    "            collection=batch_fc,\n",
    "            reducer=ee.Reducer.mean().combine(ee.Reducer.stdDev(), None, True),\n",
    "            scale=250,\n",
    "            tileScale=4\n",
    "        )\n",
    "        \n",
    "        # Add the year as a property to every feature in this year's result\n",
    "        stats_with_year = stats.map(lambda f: f.set('year', year))\n",
    "        accumulated_results.append(stats_with_year)\n",
    "\n",
    "    # Flatten the list of collections into one single collection for export\n",
    "    final_batch_fc = ee.FeatureCollection(accumulated_results).flatten()\n",
    "\n",
    "    # Define Export\n",
    "    description = f\"WDPA_Batch_{batch_index}_MODIS_{current_date}\"\n",
    "    \n",
    "    # Select specific properties to export to keep CSV clean\n",
    "    # Ensure 'wdpaid' matches the actual column name in your GPKG\n",
    "    selectors = ['wdpaid', 'year', 'NDVI_mean', 'NDVI_stdDev', 'EVI_mean', 'EVI_stdDev', 'source_file']\n",
    "\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=final_batch_fc,\n",
    "        description=description,\n",
    "        folder=EXPORT_FOLDER,\n",
    "        fileFormat='CSV',\n",
    "        selectors=selectors \n",
    "    )\n",
    "    \n",
    "    check_queue_and_wait()\n",
    "    task.start()\n",
    "    print(f\" -> Submitted Batch {batch_index} ({description})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zt0B3N-rVrU-"
   },
   "source": [
    "## 3. Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1238002,
     "status": "ok",
     "timestamp": 1750060420364,
     "user": {
      "displayName": "Gabriel Ortega-Solis",
      "userId": "18125736399926922342"
     },
     "user_tz": -120
    },
    "id": "zIkniRt9VrU_",
    "outputId": "f557e880-513a-486a-d790-f7474de3eec8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 108961 GPKG files. Processing in batches of 50...\n",
      "Processing Batch 1 with 50 files...\n",
      " -> Submitted Batch 1 (WDPA_Batch_1_MODIS_20251212)\n",
      "Processing Batch 2 with 50 files...\n",
      " -> Submitted Batch 2 (WDPA_Batch_2_MODIS_20251212)\n",
      "Processing Batch 3 with 50 files...\n",
      " -> Submitted Batch 3 (WDPA_Batch_3_MODIS_20251212)\n",
      "Processing Batch 4 with 50 files...\n",
      " -> Submitted Batch 4 (WDPA_Batch_4_MODIS_20251212)\n",
      "Processing Batch 5 with 50 files...\n",
      " -> Submitted Batch 5 (WDPA_Batch_5_MODIS_20251212)\n",
      "Processing Batch 6 with 50 files...\n",
      " -> Submitted Batch 6 (WDPA_Batch_6_MODIS_20251212)\n",
      "Processing Batch 7 with 50 files...\n",
      " -> Submitted Batch 7 (WDPA_Batch_7_MODIS_20251212)\n",
      "Processing Batch 8 with 50 files...\n",
      " -> Submitted Batch 8 (WDPA_Batch_8_MODIS_20251212)\n",
      "Processing Batch 9 with 50 files...\n",
      " -> Submitted Batch 9 (WDPA_Batch_9_MODIS_20251212)\n",
      "Processing Batch 10 with 50 files...\n",
      " -> Submitted Batch 10 (WDPA_Batch_10_MODIS_20251212)\n",
      "Processing Batch 11 with 50 files...\n",
      " -> Submitted Batch 11 (WDPA_Batch_11_MODIS_20251212)\n",
      "Processing Batch 12 with 50 files...\n",
      " -> Submitted Batch 12 (WDPA_Batch_12_MODIS_20251212)\n",
      "Processing Batch 13 with 50 files...\n",
      " -> Submitted Batch 13 (WDPA_Batch_13_MODIS_20251212)\n",
      "Processing Batch 14 with 50 files...\n",
      " -> Submitted Batch 14 (WDPA_Batch_14_MODIS_20251212)\n",
      "Processing Batch 15 with 50 files...\n",
      " -> Submitted Batch 15 (WDPA_Batch_15_MODIS_20251212)\n",
      "Processing Batch 16 with 50 files...\n",
      " -> Submitted Batch 16 (WDPA_Batch_16_MODIS_20251212)\n",
      "Processing Batch 17 with 50 files...\n",
      " -> Submitted Batch 17 (WDPA_Batch_17_MODIS_20251212)\n",
      "Processing Batch 18 with 50 files...\n",
      " -> Submitted Batch 18 (WDPA_Batch_18_MODIS_20251212)\n",
      "Processing Batch 19 with 50 files...\n",
      " -> Submitted Batch 19 (WDPA_Batch_19_MODIS_20251212)\n",
      "Processing Batch 20 with 50 files...\n",
      " -> Submitted Batch 20 (WDPA_Batch_20_MODIS_20251212)\n",
      "Processing Batch 21 with 50 files...\n",
      " -> Submitted Batch 21 (WDPA_Batch_21_MODIS_20251212)\n",
      "Processing Batch 22 with 50 files...\n",
      " -> Submitted Batch 22 (WDPA_Batch_22_MODIS_20251212)\n",
      "Processing Batch 23 with 50 files...\n",
      " -> Submitted Batch 23 (WDPA_Batch_23_MODIS_20251212)\n",
      "Processing Batch 24 with 50 files...\n",
      " -> Submitted Batch 24 (WDPA_Batch_24_MODIS_20251212)\n",
      "Processing Batch 25 with 50 files...\n",
      " -> Submitted Batch 25 (WDPA_Batch_25_MODIS_20251212)\n",
      "Processing Batch 26 with 50 files...\n",
      " -> Submitted Batch 26 (WDPA_Batch_26_MODIS_20251212)\n",
      "Processing Batch 27 with 50 files...\n",
      " -> Submitted Batch 27 (WDPA_Batch_27_MODIS_20251212)\n",
      "Processing Batch 28 with 50 files...\n",
      " -> Submitted Batch 28 (WDPA_Batch_28_MODIS_20251212)\n",
      "Processing Batch 29 with 50 files...\n",
      " -> Submitted Batch 29 (WDPA_Batch_29_MODIS_20251212)\n",
      "Processing Batch 30 with 50 files...\n",
      " -> Submitted Batch 30 (WDPA_Batch_30_MODIS_20251212)\n",
      "Processing Batch 31 with 50 files...\n",
      " -> Submitted Batch 31 (WDPA_Batch_31_MODIS_20251212)\n",
      "Processing Batch 32 with 50 files...\n",
      " -> Submitted Batch 32 (WDPA_Batch_32_MODIS_20251212)\n",
      "Processing Batch 33 with 50 files...\n",
      " -> Submitted Batch 33 (WDPA_Batch_33_MODIS_20251212)\n",
      "Processing Batch 34 with 50 files...\n",
      " -> Submitted Batch 34 (WDPA_Batch_34_MODIS_20251212)\n",
      "Processing Batch 35 with 50 files...\n",
      " -> Submitted Batch 35 (WDPA_Batch_35_MODIS_20251212)\n",
      "Processing Batch 36 with 50 files...\n",
      " -> Submitted Batch 36 (WDPA_Batch_36_MODIS_20251212)\n",
      "Processing Batch 37 with 50 files...\n",
      " -> Submitted Batch 37 (WDPA_Batch_37_MODIS_20251212)\n",
      "Processing Batch 38 with 50 files...\n",
      " -> Submitted Batch 38 (WDPA_Batch_38_MODIS_20251212)\n",
      "Processing Batch 39 with 50 files...\n",
      " -> Submitted Batch 39 (WDPA_Batch_39_MODIS_20251212)\n",
      "Processing Batch 40 with 50 files...\n",
      " -> Submitted Batch 40 (WDPA_Batch_40_MODIS_20251212)\n",
      "Processing Batch 41 with 50 files...\n",
      " -> Submitted Batch 41 (WDPA_Batch_41_MODIS_20251212)\n",
      "Processing Batch 42 with 50 files...\n",
      " -> Submitted Batch 42 (WDPA_Batch_42_MODIS_20251212)\n",
      "Processing Batch 43 with 50 files...\n",
      " -> Submitted Batch 43 (WDPA_Batch_43_MODIS_20251212)\n",
      "Processing Batch 44 with 50 files...\n",
      " -> Submitted Batch 44 (WDPA_Batch_44_MODIS_20251212)\n",
      "Processing Batch 45 with 50 files...\n",
      " -> Submitted Batch 45 (WDPA_Batch_45_MODIS_20251212)\n",
      "Processing Batch 46 with 50 files...\n",
      " -> Submitted Batch 46 (WDPA_Batch_46_MODIS_20251212)\n",
      "Processing Batch 47 with 50 files...\n",
      " -> Submitted Batch 47 (WDPA_Batch_47_MODIS_20251212)\n",
      "Processing Batch 48 with 50 files...\n",
      " -> Submitted Batch 48 (WDPA_Batch_48_MODIS_20251212)\n",
      "Processing Batch 49 with 50 files...\n",
      " -> Submitted Batch 49 (WDPA_Batch_49_MODIS_20251212)\n",
      "Processing Batch 50 with 50 files...\n",
      " -> Submitted Batch 50 (WDPA_Batch_50_MODIS_20251212)\n",
      "Processing Batch 51 with 50 files...\n",
      " -> Submitted Batch 51 (WDPA_Batch_51_MODIS_20251212)\n",
      "Processing Batch 52 with 50 files...\n",
      " -> Submitted Batch 52 (WDPA_Batch_52_MODIS_20251212)\n",
      "Processing Batch 53 with 50 files...\n",
      " -> Submitted Batch 53 (WDPA_Batch_53_MODIS_20251212)\n",
      "Processing Batch 54 with 50 files...\n",
      " -> Submitted Batch 54 (WDPA_Batch_54_MODIS_20251212)\n",
      "Processing Batch 55 with 50 files...\n",
      " -> Submitted Batch 55 (WDPA_Batch_55_MODIS_20251212)\n",
      "Processing Batch 56 with 50 files...\n",
      " -> Submitted Batch 56 (WDPA_Batch_56_MODIS_20251212)\n",
      "Processing Batch 57 with 50 files...\n",
      " -> Submitted Batch 57 (WDPA_Batch_57_MODIS_20251212)\n",
      "Processing Batch 58 with 50 files...\n",
      " -> Submitted Batch 58 (WDPA_Batch_58_MODIS_20251212)\n",
      "Processing Batch 59 with 50 files...\n",
      " -> Submitted Batch 59 (WDPA_Batch_59_MODIS_20251212)\n",
      "Processing Batch 60 with 50 files...\n",
      " -> Submitted Batch 60 (WDPA_Batch_60_MODIS_20251212)\n",
      "Processing Batch 61 with 50 files...\n",
      " -> Submitted Batch 61 (WDPA_Batch_61_MODIS_20251212)\n",
      "Processing Batch 62 with 50 files...\n",
      " -> Submitted Batch 62 (WDPA_Batch_62_MODIS_20251212)\n",
      "Processing Batch 63 with 50 files...\n",
      " -> Submitted Batch 63 (WDPA_Batch_63_MODIS_20251212)\n",
      "Processing Batch 64 with 50 files...\n",
      " -> Submitted Batch 64 (WDPA_Batch_64_MODIS_20251212)\n",
      "Processing Batch 65 with 50 files...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    if not os.path.exists(INPUT_FOLDER):\n",
    "        print(f\"Error: Input folder '{INPUT_FOLDER}' not found.\")\n",
    "        return\n",
    "\n",
    "    # Get list of files\n",
    "    all_files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith('.gpkg')]\n",
    "    total_files = len(all_files)\n",
    "    \n",
    "    if total_files == 0:\n",
    "        print(\"No .gpkg files found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {total_files} GPKG files. Processing in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "    current_batch_gdfs = []\n",
    "    batch_counter = 1\n",
    "\n",
    "    for i, filename in enumerate(all_files):\n",
    "        filepath = os.path.join(INPUT_FOLDER, filename)\n",
    "        \n",
    "        # 1. Read and Clean Local Data\n",
    "        gdf = read_and_clean_gpkg(filepath)\n",
    "        \n",
    "        if gdf is not None and not gdf.empty:\n",
    "            current_batch_gdfs.append(gdf)\n",
    "\n",
    "        # 2. Check if we should process the batch\n",
    "        is_batch_full = len(current_batch_gdfs) >= BATCH_SIZE\n",
    "        is_last_file = (i == total_files - 1)\n",
    "\n",
    "        if (is_batch_full or is_last_file) and current_batch_gdfs:\n",
    "            print(f\"Processing Batch {batch_counter} with {len(current_batch_gdfs)} files...\")\n",
    "            \n",
    "            try:\n",
    "                # Combine Python GDFs into one\n",
    "                merged_gdf = pd.concat(current_batch_gdfs, ignore_index=True)\n",
    "                \n",
    "                # Convert to Earth Engine FeatureCollection ONCE per batch\n",
    "                ee_batch_fc = geemap.geopandas_to_ee(merged_gdf)\n",
    "                \n",
    "                # Submit to Earth Engine\n",
    "                submit_batch_export(ee_batch_fc, batch_counter, [START_YEAR, END_YEAR])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error submitting Batch {batch_counter}: {e}\")\n",
    "                # Optional: You could log failed batch IDs to a file here\n",
    "\n",
    "            # Reset Accumulator for next batch\n",
    "            current_batch_gdfs = []\n",
    "            batch_counter += 1\n",
    "\n",
    "    print(\"All batches submitted.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geostatistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
