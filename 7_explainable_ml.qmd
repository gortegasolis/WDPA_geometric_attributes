---
title: "Explainable machine learning"
format: html
---
### Explainable machine learning
#### Interactions

```{r}
pacman::p_load(hstats, ggpubr, parallel, future.apply)

names(ml_fits) <- responses

plan(multisession, workers = 50)

get_interactions <- function(model, fileid = NULL, background_data = NULL) {
    # Calculate hstat
    hstat <- hstats(model, X = background_data)

    h2val <- hstat$h2$num / hstat$h2$denom
    h2val <- round(h2val, 2)

    saveRDS(hstat, file = str_glue("rds_backups/{fileid}_hstat.rds"))

    plot_all <- plot(hstat, normalize = T, squared = T) +
        labs(
            title = "",
            x = bquote("HÂ² (normalized) =" ~ .(h2val)),
            y = ""
        ) +
        theme_pubr() +
        theme(
            strip.background = element_blank()
        )

    ggsave(plot = plot_all, filename = str_glue("figures/{fileid}_all_interactions_strength.svg"), width = 45, height = 15, units = "cm")
}

# Run the loop
# Pre-slice models and data outside the future_lapply call
input_list <- sapply(names(ml_fits), function(response) {
    # Extract the recipe and bake it
    recipe <- extract_workflow(ml_fits[[response]]) %>% extract_recipe()
    baked_data <- bake(recipe, new_data = ml_data)

    # Extract the fitted model
    model <- extract_fit_parsnip(ml_fits[[response]])

    list(
        model = model,
        fileid = response,
        background_data = baked_data %>% select(-all_of(response))
    )
}, USE.NAMES = T, simplify = F)

# Then pass only the necessary slice to each worker (much lighter!)
future_lapply(input_list, function(x) {
    tryCatch(
        get_interactions(
            model = x$model,
            fileid = x$fileid,
            background_data = x$background_data
        ),
        error = function(e) {
            stop(str_glue("Error in response {x$fileid}: {e$message}"))
            NULL
        }
    )
}, future.scheduling = TRUE, future.seed = TRUE)
```

#### Partial dependence plots

```{r}
pacman::p_load(vip, patchwork, tagger)

plot_partial_dependence <- function(response, x_axis_var, interacting_var, background_data = NULL) {
    f_model <- extract_fit_parsnip(ml_fits[[response]])
    processed_train <- bake(prep(ml_recipes[[response]]), new_data = background_data)
    # Generate partial dependence data
    plot <- hstats::partial_dep(f_model$fit, v = x_axis_var, BY = interacting_var, X = processed_train)$data %>%
        pivot_longer(cols = all_of(x_axis_var), names_to = "interacting_var", values_to = "interacting_var_value") %>%
        mutate(response = response)

    return(plot)
}

# Coefficient of variation of NDVI
p1 <- plot_partial_dependence(
    response = "cv_ndvi",
    x_axis_var = "reock",
    interacting_var = "area",
    background_data = ml_train
)

p2 <- plot_partial_dependence(
    response = "cv_ndvi",
    x_axis_var = "fractaldimension",
    interacting_var = "area",
    background_data = ml_train
)

# Coefficient of variation of elevation
p3 <- plot_partial_dependence(
    response = "elevation_cv",
    x_axis_var = "reock",
    interacting_var = "area",
    background_data = ml_train
)

p4 <- plot_partial_dependence(
    response = "elevation_cv",
    x_axis_var = "fractaldimension",
    interacting_var = "area",
    background_data = ml_train
)

# Number of climates
p5 <- plot_partial_dependence(
    response = "n_climates",
    x_axis_var = "reock",
    interacting_var = "area",
    background_data = ml_train
)

p6 <- plot_partial_dependence(
    response = "n_climates",
    x_axis_var = "fractaldimension",
    interacting_var = "area",
    background_data = ml_train
)

# Shannon climates
p7 <- plot_partial_dependence(
    response = "shannon_climates",
    x_axis_var = "reock",
    interacting_var = "area",
    background_data = ml_train
)

p8 <- plot_partial_dependence(
    response = "shannon_climates",
    x_axis_var = "fractaldimension",
    interacting_var = "area",
    background_data = ml_train
)

# Landcover categories
p9 <- plot_partial_dependence(
    response = "n_landcover",
    x_axis_var = "reock",
    interacting_var = "area",
    background_data = ml_train
)

p10 <- plot_partial_dependence(
    response = "n_landcover",
    x_axis_var = "fractaldimension",
    interacting_var = "area",
    background_data = ml_train
)

# Shannon landcover diversity
p11 <- plot_partial_dependence(
    response = "shannon_landcover",
    x_axis_var = "fractaldimension",
    interacting_var = "area",
    background_data = ml_train
)

p12 <- plot_partial_dependence(
    response = "shannon_landcover",
    x_axis_var = "reock",
    interacting_var = "area",
    background_data = ml_train
)

p13 <- plot_partial_dependence(
    response = "shannon_landcover",
    x_axis_var = "elongation",
    interacting_var = "area",
    background_data = ml_train
)

p <- rbind(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10, p11, p12) %>%
    mutate(response = factor(response, levels = c("cv_ndvi", "elevation_cv", "n_climates", "shannon_climates", "n_landcover", "shannon_landcover")),
           interacting_var = factor(interacting_var, levels = c("reock_index", "fractaldimension"))) %>%
    ggplot(., aes(x = interacting_var_value, y = y, color = area)) +
    geom_line() +
    facet_grid(
        response ~ interacting_var,
        scales = "free",
        axes = "all",
        axis.labels = "margins",
        labeller = as_labeller(c(
            reock_index = "Reock index",
            fractaldimension = "Fractal dimension",
            cv_ndvi = "CV-NDVI",
            elevation_cv = "CV-ELEV",
            n_climates = "N-CLIM",
            shannon_climates = "DIV-CLIM",
            n_landcover = "N-LC",
            shannon_landcover = "DIV-LC"
        )),
        switch = "both"
    ) +
    labs(color = "Area", y = "Partial dependence") +
    tag_facets(tag_levels = "a", tag_prefix = "(", tag_suffix = ")") +
    theme_pubr() +
    theme(
        text = element_text(size = 14),
        legend.position = "right",
        strip.text = element_text(size = 14),
        strip.background = element_blank(),
        axis.title.x = element_blank(),
        strip.placement = "outside",
        tagger.panel.tag.text = element_text(size = 16, face = "bold")
    )

ggsave("figures/partial_dependence_combined.svg",
    plot = p, width = 11, height = 17, units = "in", dpi = 300, bg = "white"
)

```

### Mapping residuals
```{r}
pacman::p_load(sf, ggspatial, rnaturalearth, rnaturalearthdata, ggplot2, ggnewscale, ggpubr, dplyr)

data <- left_join(data, 
readRDS("Data/wdpa.rds") %>% select(WDPAID, decimallongitude, decimallatitude), by = "WDPAID")

world <- ne_countries(scale = "medium", returnclass = "sf")

st_crs(world) <- 4326

# Create a regular grid of points (lat/lon) covering the world extent
bbox <- st_bbox(world)
grid_sf <- st_make_grid(world, what = "polygons", cellsize = c(15, 15), square = TRUE) %>% 
st_as_sf()

pa_coords <- st_as_sf(data, coords = c("decimallongitude", "decimallatitude"), crs = 4326, remove = FALSE)

rm(pred_all)
for (x in names(ml_fits)) {
    try({
        # Extract the recipe and bake it
        recipe <- extract_workflow(ml_fits[[x]]) %>% extract_recipe()
        baked_data <- bake(recipe, new_data = data) %>%
            mutate(WDPAID = data$WDPAID)

        # Extract the fitted model
        model <- extract_fit_parsnip(ml_fits[[x]])

        # Predict on the entire dataset
        predictions <- predict(model, new_data = baked_data) %>%
            bind_cols(baked_data %>% select("WDPAID")) %>%
            rename(!!paste0(x, "_predicted") := .pred)

        if(exists("pred_all")) {
            pred_all <- left_join(pred_all, predictions, by = "WDPAID", suffix = c("", paste0("_", x)))
        } else {
            pred_all <- predictions
        }
    })
}

data <- left_join(data, pred_all, by = "WDPAID")

sf_data <- st_read("Data/Work_data_wdpa.gpkg") %>%
filter(wdpaid %in% unique(data$WDPAID))

sf_data$wdpaid <- as.factor(sf_data$wdpaid)

sf_data <- left_join(sf_data, data, by = c("wdpaid" = "WDPAID"))

for (x in names(ml_fits)) {
    try({
        temp <- sf_data
        temp$residuals <- temp[[paste0(x, "_predicted")]] - temp[[x]]

        # Plot residuals
        p <- ggplot() +
            geom_sf(data = world, fill = "lightgray", color = "white") +
            geom_sf(data = temp, aes(fill = residuals), color = NA) +
            geom_sf(data = grid_sf, color = "gray", size = 0.1, alpha = 0.5, fill = NA, lty = "dashed") +
            scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
            labs(fill = "Residuals") +
            theme_pubr() +
            theme(
            legend.position = "bottom"
            ) +
            coord_sf(crs = "+proj=moll +lon_0=0 +datum=WGS84 +units=m +no_defs")

        ggsave(filename = str_glue("figures/{x}_residuals_map.svg"), plot = p, width = 10, height = 6, units = "in", dpi = 300)
    })
}
```